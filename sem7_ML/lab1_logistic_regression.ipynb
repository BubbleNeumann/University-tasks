{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        # dim - размерность входных данных.\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели, \n",
    "# используя accuracy_score из пакета SciKit-Learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`. \n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self):\n",
    "        print('Hello, brother!')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте дополнительные метрики из пакета sklearn для анализа \"глупого классификатора\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя те же метрики, проанализируйте модель логистической регрессии. Объясните результат.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предложите способ улучшения качества модели. Подсказка: добавление дубликатов в данные.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель но этом наборе данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проанализируйте качество модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, x^2, ...).\n",
    "# Объедините трансформированные данные с исходными.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 'Упрощение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность: легко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модифицируйте класс логистической регрессии так, чтобы в нём не использовалась сигмоида.\n",
    "# То есть вывод о предсказанном классе должен делаться на основе значений \"до сигмоиды\".\n",
    "# Вспомогательная ссылка: https://en.wikipedia.org/wiki/Logit\n",
    "# Подсказка: взгляните на то, при каких входных `x` значение сигмоды больше 0.5 и меньше 0.5.\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        p = sigmoid(x)\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторите эксперимент из задания 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Softmax классификатор.</b> Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс классификатора, основанного на функции Softmax.\n",
    "Алгоритм работы данного классификатора:\n",
    "x - вектор (экземпляр данных) размерности dim.\n",
    "W - матрица весов размерности [dim, n_classes].\n",
    "\n",
    "Ответ классификатора формируется как:\n",
    "logits = x * W - матричное умножение\n",
    "p = softmax(logits)\n",
    "class_id = argmax(p)\n",
    "\n",
    "Для данного классификатора требуется модифицировать алгоритм обучения в методе fit.\n",
    "\n",
    "Вспомогательные ресурсы:\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\"\"\"\n",
    "\n",
    "class SoftmaxClassificator:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор на наборе данных из задания 1 (опционально). Оцените точность модели.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
